<!DOCTYPE HTML>
<html lang="en">
  <head>
	<meta name="google-site-verification" content="uWFfoAcBv8YA8PJ4JBpN1AaG8Q8Mcmzp7b_YxzeQ0zQ" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Junhui Lin</title>

    <meta name="author" content="Junhui Lin">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:980px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:70%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Junhui Lin
                </p>
                <p>
Hi! I'm a final-year undergraduate student at Beijing Normal University, Beijing, China since 2022, majoring in Artificial Intelligence under the supervision of <a href="https://www.yfhuang.com/">Yuanfei Huang</a>. I am also a member of the <a href="https://vmcl.bnu.edu.cn/">Intelligent Media Computing Lab</a>. 

Besides, I completed a research internship under the supervision of <a href="https://ha0tang.github.io/">Hao Tang</a> (Jul 2025 – Oct 2025).<br><br>
				
My research interests lie in <strong>Computer Vision</strong> , <strong>Representation Learning</strong>, with specialized expertise in:</p>
<ul>
  <em>Image and Video generation</em>
  <em>Representation Alignment for generation</em>
  <em>Low-level vision such as frame interpolation, image restoration</em>
</ul>
From the long term, I am passionate about exploring integrating prior-knowledge training to achieve flexible and effective multi-conditional control, advancing cutting-edge model architectures to enhance visual understanding and task performance, while driving down inference latency and computational cost.

                </p>
                <p style="text-align:center">
                  <a href="mailto:202211081025@mail.bnu.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=1RFruLYAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/junhui-lin-171518383/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/kmp1001/">Github</a>
                </p>
              </td>
              <td style="padding:1%;width:25%;max-width:25%">
                <img src='images/photo.jpg' class="rounded-image" style="max-width: 100%; height: auto;">
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
				<div style="height: 0.5em;"></div>
                (* Equal Contribution;‡ Corresponding Author)
                <p>
                  I'm interested in computer vision, generative AI, multimodal learning, image processing. 
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <!-- UniVid -->
    <tr>
      <td style="padding:15px;width:34%;vertical-align:middle">
        <video id="dollyzoom" autoplay muted loop style="max-width: 100%; height: auto;">
          <source src="videos/A_dolphin_leaps_out_of_the_oce_.mp4" type="video/mp4">
        </video>
      </td>
      <td style="padding:15px;width:66%;vertical-align:middle">
        <strong style="font-size: 18px;">UniVid: The Open-Source Unified Video Model</strong>
        <br><br>
		Jiabin Luo*, <strong>Junhui Lin*</strong>, Zeyu Zhang, Biao Wu, Meng Fang, Ling Chen, Hao Tang‡
        <br><br>
        <em>Under Review, 2025</em>
        <br><br>
        <a href="https://aigeeksgroup.github.io/UniVid/"><strong>[Website]</strong></a> <a href="https://arxiv.org/abs/2509.24200"><strong>[PDF]</strong></a> <a href="https://github.com/AIGeeksGroup/UniVid/"><strong>[Code]</strong></a> 
      </td>
    </tr>
			  
	<!-- DeflareMamba -->
	<tr>
	  <td style="padding:15px;width:34%;vertical-align:middle">
	    <!-- 用静态图片替代视频： -->
	    <img id="deflare" src="images/2025ACMMM_DeflareMamba.png"
	         alt="Deflare preview"
	         style="max-width: 100%; height: auto;" loading="lazy">
	  </td>
	  <td style="padding:15px;width:66%;vertical-align:middle">
	    <strong style="font-size: 18px;">DeflareMamba: Hierarchical Vision Mamba for Contextually Consistent Lens Flare Removal</strong>
	    <br><br>
	    Yihang Huang, Yuanfei Huang‡, <strong>Junhui Lin</strong>, Hua Huang
	    <br><br>
	    <em>ACMMM, 2025</em>
	    <br><br>
		<a href="https://github.com/BNU-ERC-ITEA/DeflareMamba/"><strong>[Code]</strong></a> <a href="https://www.arxiv.org/pdf/2508.02113"><strong>[PDF]</strong></a> 
	  </td>
	</tr>
<!-- Projects -->
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Projects</h2>
				<div style="height: 0.5em;"></div>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <!-- VRTI -->
    <tr>
      <td style="padding:15px;width:34%;vertical-align:middle">
        <video id="dollyzoom" autoplay muted loop style="max-width: 100%; height: auto;">
          <source src="videos/VRTI.mp4" type="video/mp4">
        </video>
      </td>
      <td style="padding:15px;width:66%;vertical-align:middle">
        <strong style="font-size: 18px;">VRTI: Immersive Virtual Physics Laboratory Based on Semi-Physical Tangible Interaction</strong>
        <br><br>
		<strong>Junhui Lin</strong>, Shujun Yao, Wenzhuo Li
        <br><br>
        <em>Finished and Deployed, 2025</em>
        <br><br>
        <a href="https://h5.hlcode.com.cn/?id=NJdLaEb&f=1520127"><strong>[Video]</strong></a> 
      </td>
	</tr>

    <!-- EmoVision -->
    <tr>
      <td style="padding:15px;width:34%;vertical-align:middle">
        <video id="dollyzoom" autoplay muted loop style="max-width: 100%; height: auto;">
          <source src="videos/EmoVision_1.mp4" type="video/mp4">
        </video>
      </td>
      <td style="padding:15px;width:66%;vertical-align:middle">
        <strong style="font-size: 18px;">EmoVision: An Intelligent Psychological Healing Platform Based on Multimodal Emotion Recognition</strong>
        <br><br>
		<strong>Junhui Lin</strong>, Huang Yang, Degang Wei
        <br><br>
        <em>Open-Sourced(Congratulations we got nearly 600 stars) and won the third in National AI Innocation Competition held by Zhejing University and Baidu Inc., 2025</em>
        <br><br>
        <a href="https://drive.google.com/file/d/15aM_Sn6T_27H3xN9UgR2xmGMus8Xfv6w/view?usp=drive_link"><strong>[Video]</strong></a> <a href="https://aistudio.baidu.com/projectdetail/8376625"><strong>[Website]</strong></a> <a href="https://github.com/GabePersson/EmoVision"><strong>[Code]</strong></a> 
      </td>
	</tr>
<!-- Experiences -->
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Exploration</h2>
				<div style="height: 0.5em;"></div>
                <p>
                  I list several research topics I have previously explored, many of which are driven by broader visions and unconventional approaches beyond traditional paradigms. Although a number of these attempts did not ultimately succeed after repeated exploration, such experiences have proven especially valuable in shaping my research perspective.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<!-- VFIDiff -->
	<tr>
	  <td style="padding:15px;width:34%;vertical-align:middle">
	    <!-- 用静态图片替代视频： -->
	    <img id="deflare" src="images/VFIDiff.png"
	         alt="Deflare preview"
	         style="max-width: 100%; height: auto;" loading="lazy">
	  </td>
	  <td style="padding:15px;width:66%;vertical-align:middle">
	    <strong style="font-size: 18px;">VFIDiff: Motion-Aware Generative Multi-frame Interpolation</strong>
	    <br><br>
	    <strong>Junhui Lin</strong>n, Yuanfei Huang‡
	    <br><br>
	    <em>This work conducts a structured survey of state-of-the-art video frame interpolation (VFI) methods and outlines a roadmap toward multi-frame interpolation at arbitrary time steps. Building on flow-warping mechanisms, we derive transition probability distributions and propose VFIDiff, which formulates VFI as a sequence generation problem, enabling the generation of multiple intermediate frames in a unified diffusion-based framework.</em>
	    <br><br>
		<a href="https://github.com/kmp1001/VFIDiff"><strong>[Code]</strong></a> 
	  </td>
	</tr>
					

<!-- Awards -->

	<table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
	  <tbody>
	    <tr>
	      <td style="padding:16px;width:100%;vertical-align:middle">
	        <h2>Selected Awards</h2>
	      </td>
	    </tr>
	  </tbody>
	</table>
	
	<table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
	  <tbody>
	    <tr>
	      <td style="padding:15px 0 0 20px; width:100%; vertical-align:middle;">
	        <span style="font-weight:bolder; font-size:17px;">China National Scholarship</span>
	        <span style="font-size:17px;"> (<em>Top 1%</em>), 2025</span>
	        <br>
	        <span style="font-weight:bolder; font-size:17px;">The Third Prize in the National Artificial Intelligence Innovation Competition</span>
	        <span style="font-size:17px;"> (<em>Top 2%</em>), 2025</span>
	      </td>
	    </tr>
	  </tbody>
	</table>

	
	<hr style="width: 100%; margin-top: 30px; margin-bottom: 10px;">
	
	<table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
	  <tbody>
	    <tr>
	      <td style="padding:0;">
	        <p style="text-align:right;font-size:14px;margin:12px 0 0 0;">
	          Design and source code from
	          <a href="https://github.com/jonbarron/jonbarron_website" style="font-size:14px;">Jon Barron's website</a>.
	        </p>
	      </td>
	    </tr>
	  </tbody>
	</table>
  </body>
</html>


